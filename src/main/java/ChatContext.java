import dev.langchain4j.data.message.SystemMessage;
import dev.langchain4j.data.message.UserMessage;
import dev.langchain4j.memory.ChatMemory;
import dev.langchain4j.memory.chat.MessageWindowChatMemory;
import dev.langchain4j.model.chat.ChatModel;
import dev.langchain4j.model.openai.OpenAiChatModel;
import dev.langchain4j.model.openai.OpenAiChatModelName;

import java.time.Duration;
import java.util.Scanner;

public class ChatContext {
    public static void main(String[] args) {
        Scanner userinput;
        String cmdline;

        ChatModel cmodel = OpenAiChatModel.builder()
                .apiKey(System.getenv("OPENAI_API_KEY"))
                .modelName(OpenAiChatModelName.GPT_3_5_TURBO) // you can also use GPT_4
                .temperature(.3)                    // keep randomness low
                .timeout(java.time.Duration.ofSeconds(120))
                .maxTokens(1024)
                .build();

        ChatMemory cm = MessageWindowChatMemory.withMaxMessages(100);

        SystemMessage sysmsg = new SystemMessage("""
                    You are a polite software consultant with deep expertise in teaching AI and Machine Learning.
                """);
        cm.add(sysmsg);


        while (true) {
            System.out.print("prompt> ");

            userinput = new Scanner(System.in);
            cmdline = userinput.nextLine();

            if (cmdline.isBlank())       // If nothing, do nothing
                continue;

            UserMessage usrmsg = UserMessage.from(cmdline);   // create the prompt
            cm.add(usrmsg);                                   // Add the user prompt to the ChatMemory

            var answer = cmodel.chat(cm.messages());  // send the context as messages and save the response
            var response = answer.aiMessage().text();

            System.out.println(response);

            cm.add(UserMessage.from(response));     // Add the response from the assistant
                                                    // Could have added answer.aiMessage()
        }
    }
}
